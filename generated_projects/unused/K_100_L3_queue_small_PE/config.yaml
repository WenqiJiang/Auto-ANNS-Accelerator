---
  # Constants
  NLIST: 8192
  NPROBE: 17
  D: 128
  M: 16
  K: 256
  TOPK: 100

  QUERY_NUM: 10000

  LARGE_NUM: 99999999 # used to init the heap
  # stage 1
  OPQ_ENABLE: True
  OPQ_UNROLL_FACTOR: 4 # 4 or 8 or 16, the larger the better performance, left None if OPQ_ENABLE=False

  # stage 2
  # except last PE: compute more distances per query, last one compute less
  # e.g., nlist = 8192, PE num = 15, 
  #   each of the first 14 PEs construct 547 tables (8192 / 15 round up), 
  #   while the last constructs 534: 14 * 547 + 534 = 8192
  STAGE2_ON_CHIP: True
  STAGE2_OFF_CHIP_START_CHANNEL: 12
  PE_NUM_CENTER_DIST_COMP: 12
  # The rest variables should be caculated in python (YAML does not support arithmetics) 
  # PE_NUM_CENTER_DIST_COMP_EVEN: 14
  # CENTROIDS_PER_PARTITION_EVEN: 547
  # CENTROIDS_PER_PARTITION_LAST_PE (NLIST - PE_NUM_CENTER_DIST_COMP_EVEN * CENTROIDS_PER_PARTITION_EVEN)

  # stage 3
  # 2 levels, first level 2 queue, second level 1 queue
  STAGE_3_PRIORITY_QUEUE_LEVEL: 2
  STAGE_3_PRIORITY_QUEUE_L1_NUM: 2

  # stage 4
  # except last PE: construct more tables per query, last one construct less
  # e.g., nprobe = 17, PE num = 6, each of the first 5 PEs construct 3 tables, 
  #   while the last constructs 2: 5 * 3 + 2 = 17
  PE_NUM_TABLE_CONSTRUCTION: 9 
  # PE_NUM_TABLE_CONSTRUCTION_LARGER: 5 # 1
  # PE_NUM_TABLE_CONSTRUCTION_SMALLER: 1
  # NPROBE_PER_TABLE_CONSTRUCTION_PE_LARGER: 3 #9
  # NPROBE_PER_TABLE_CONSTRUCTION_PE_SMALLER: 2 #8

  # stage 5
  # (HBM_CHANNEL_NUM * 3 / STAGE5_COMP_PE_NUM) must be integar
  # e.g., default 1 HBM channel -> 3 PQ code streams -> STAGE5_COMP_PE_NUM = 3 * HBM_CHANNEL_NUM
  # e.g., merge content of 1 HBM channel to 1 PQ code stream -> STAGE5_COMP_PE_NUM = HBM_CHANNEL_NUM
  # e.g., merge content of 2 HBM channels to 1 PQ code stream -> STAGE5_COMP_PE_NUM = HBM_CHANNEL_NUM / 2
  HBM_CHANNEL_NUM: 10 # PQ code stream num = 3 * HBM_CHANNEL_NUM
  STAGE5_COMP_PE_NUM: 5

  # stage 6
  # there could be a sorting network before the priority queue group (SORT_GROUP_ENABLE)
  #   if not, set SORT_GROUP_ENABLE to False, and SORT_GROUP_NUM to 0 or None
  # number of 16 outputs per cycle, e.g., HBM channel num = 10, comp PE num = 30, then 
  #   SORT_GROUP_NUM = 2; if HBM channel = 12, PE_num = 36, then SORT_GROUP_NUM = 3
  SORT_GROUP_ENABLE: False
  SORT_GROUP_NUM: 0
  # SORT_GROUP_ENABLE: True
  # SORT_GROUP_NUM: 2
  STAGE_6_PRIORITY_QUEUE_LEVEL: 3 # supported level num: 2 or 3
  # only fill STAGE_6_PRIORITY_QUEUE_L2_NUM, STAGE_6_STREAM_PER_L2_QUEUE_LARGER, STAGE_6_STREAM_PER_L2_QUEUE_SMALLER
  #   when STAGE_6_PRIORITY_QUEUE_LEVEL = 3, else left them blank
  # Must subject to: L1 stream num = STAGE5_COMP_PE_NUM * 2 = 
  # (STAGE_6_PRIORITY_QUEUE_L2_NUM - 1) * STAGE_6_STREAM_PER_L2_QUEUE_LARGER + STAGE_6_STREAM_PER_L2_QUEUE_SMALLER
  STAGE_6_PRIORITY_QUEUE_L2_NUM: 2
  STAGE_6_STREAM_PER_L2_QUEUE_LARGER: 6
  STAGE_6_STREAM_PER_L2_QUEUE_SMALLER: 4

  # Dataset config
  DB_SCALE: "100M" # 1M to 1000M
  # DB size in bytes, the contents will be evenly distributed to all bank
  DB_BYTES: 2135895680

  # Data directory (don't add "/" after the dir)
  #   e.g., dir=/home/wejiang/saved_npy_data/FPGA_data_SIFT100M_OPQ16,IVF8192,PQ16_HBM_10_banks, 
  #     then the content for HBM0 is:
  #     /home/wejiang/saved_npy_data/FPGA_data_SIFT100M_OPQ16,IVF8192,PQ16_HBM_10_banks/HBM_bank_0_raw
  DATA_DIR: "/home/wejiang/saved_npy_data/FPGA_data_SIFT100M_OPQ16,IVF8192,PQ16_HBM_10_banks"
  GT_DIR: "/home/wejiang/saved_npy_data/gnd/"

  # FPGA frequency
  FREQ: 140
